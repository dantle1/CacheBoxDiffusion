{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdantle4564\u001b[0m (\u001b[33mdantle4564-uc-santa-barbara\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['444.namd-120B',\n",
       " '458.sjeng-31B',\n",
       " '454.calculix-104B',\n",
       " '605.mcf_s-484B',\n",
       " '482.sphinx3-1522B',\n",
       " '459.GemsFDTD-1211B',\n",
       " '481.wrf-196B',\n",
       " '641.leela_s-334B',\n",
       " '473.astar-42B',\n",
       " '401.bzip2-7B',\n",
       " '453.povray-576B',\n",
       " '649.fotonik3d_s-1B',\n",
       " '623.xalancbmk_s-592B',\n",
       " '410.bwaves-1963B',\n",
       " '625.x264_s-18B',\n",
       " '482.sphinx3-234B',\n",
       " '623.xalancbmk_s-700B',\n",
       " '648.exchange2_s-72B',\n",
       " '641.leela_s-602B',\n",
       " '625.x264_s-39B',\n",
       " '459.GemsFDTD-1418B',\n",
       " '654.roms_s-842B',\n",
       " '482.sphinx3-1100B',\n",
       " '644.nab_s-5853B',\n",
       " '649.fotonik3d_s-8225B',\n",
       " '605.mcf_s-665B',\n",
       " '401.bzip2-226B',\n",
       " '429.mcf-217B',\n",
       " '641.leela_s-1083B',\n",
       " '482.sphinx3-1395B',\n",
       " '483.xalancbmk-127B',\n",
       " '481.wrf-455B',\n",
       " '603.bwaves_s-5359B',\n",
       " '444.namd-321B',\n",
       " '644.nab_s-12521B',\n",
       " '436.cactusADM-1804B',\n",
       " '619.lbm_s-3766B',\n",
       " '473.astar-153B',\n",
       " '456.hmmer-191B',\n",
       " '435.gromacs-134B',\n",
       " '648.exchange2_s-1712B',\n",
       " '654.roms_s-294B',\n",
       " '605.mcf_s-782B',\n",
       " '447.dealII-3B',\n",
       " '437.leslie3d-149B',\n",
       " '605.mcf_s-1644B',\n",
       " '462.libquantum-714B',\n",
       " '435.gromacs-226B',\n",
       " '648.exchange2_s-584B',\n",
       " '644.nab_s-12459B',\n",
       " '429.mcf-51B',\n",
       " '603.bwaves_s-2609B',\n",
       " '464.h264ref-57B',\n",
       " '623.xalancbmk_s-165B',\n",
       " '429.mcf-192B',\n",
       " '482.sphinx3-417B',\n",
       " '620.omnetpp_s-874B',\n",
       " '481.wrf-816B',\n",
       " '603.bwaves_s-1740B',\n",
       " '459.GemsFDTD-1169B',\n",
       " '437.leslie3d-232B',\n",
       " '654.roms_s-1007B',\n",
       " '620.omnetpp_s-141B',\n",
       " '649.fotonik3d_s-7084B',\n",
       " '605.mcf_s-1554B',\n",
       " '641.leela_s-1052B',\n",
       " '410.bwaves-945B',\n",
       " '437.leslie3d-271B',\n",
       " '644.nab_s-7928B',\n",
       " '625.x264_s-12B',\n",
       " '444.namd-23B',\n",
       " '481.wrf-1281B',\n",
       " '464.h264ref-64B',\n",
       " '483.xalancbmk-736B',\n",
       " '433.milc-337B',\n",
       " '603.bwaves_s-2931B',\n",
       " '464.h264ref-30B',\n",
       " '453.povray-800B',\n",
       " '649.fotonik3d_s-1176B',\n",
       " '410.bwaves-2097B',\n",
       " '444.namd-426B',\n",
       " '471.omnetpp-188B',\n",
       " '619.lbm_s-4268B',\n",
       " '435.gromacs-111B',\n",
       " '437.leslie3d-134B',\n",
       " '603.bwaves_s-1080B',\n",
       " '483.xalancbmk-716B',\n",
       " '654.roms_s-1070B',\n",
       " '605.mcf_s-994B',\n",
       " '648.exchange2_s-1227B',\n",
       " '437.leslie3d-273B',\n",
       " '453.povray-252B',\n",
       " '654.roms_s-1021B',\n",
       " '641.leela_s-862B',\n",
       " '605.mcf_s-1152B',\n",
       " '644.nab_s-9322B',\n",
       " '454.calculix-460B',\n",
       " '437.leslie3d-265B',\n",
       " '623.xalancbmk_s-202B',\n",
       " '641.leela_s-800B',\n",
       " '654.roms_s-293B',\n",
       " '625.x264_s-33B',\n",
       " '434.zeusmp-10B',\n",
       " '459.GemsFDTD-765B',\n",
       " '619.lbm_s-2677B',\n",
       " '435.gromacs-228B',\n",
       " '481.wrf-1170B',\n",
       " '416.gamess-875B',\n",
       " '462.libquantum-1343B',\n",
       " '649.fotonik3d_s-10881B',\n",
       " '641.leela_s-149B',\n",
       " '603.bwaves_s-891B',\n",
       " '605.mcf_s-1536B',\n",
       " '603.bwaves_s-3699B',\n",
       " '648.exchange2_s-1699B',\n",
       " '625.x264_s-20B',\n",
       " '481.wrf-1254B',\n",
       " '459.GemsFDTD-1491B',\n",
       " '458.sjeng-1088B',\n",
       " '628.pop2_s-17B',\n",
       " '433.milc-274B',\n",
       " '648.exchange2_s-387B',\n",
       " '605.mcf_s-472B',\n",
       " '429.mcf-184B',\n",
       " '401.bzip2-277B',\n",
       " '623.xalancbmk_s-10B',\n",
       " '456.hmmer-88B',\n",
       " '648.exchange2_s-1247B',\n",
       " '444.namd-33B',\n",
       " '456.hmmer-327B',\n",
       " '458.sjeng-767B',\n",
       " '401.bzip2-38B',\n",
       " '482.sphinx3-1297B',\n",
       " '619.lbm_s-2676B',\n",
       " '429.mcf-22B',\n",
       " '453.povray-887B',\n",
       " '433.milc-127B',\n",
       " '654.roms_s-1613B',\n",
       " '654.roms_s-1390B',\n",
       " '459.GemsFDTD-1320B',\n",
       " '648.exchange2_s-353B',\n",
       " '654.roms_s-523B',\n",
       " '648.exchange2_s-1511B',\n",
       " '444.namd-44B',\n",
       " '444.namd-166B',\n",
       " '623.xalancbmk_s-325B',\n",
       " '473.astar-359B',\n",
       " '648.exchange2_s-210B',\n",
       " '464.h264ref-97B',\n",
       " '458.sjeng-283B']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "filename = \"/home/pranjali_jain/NCS/sparse-matrices/SPEC/SPEC189_2config/1-64-12/TRAIN/MISS\"\n",
    "os.listdir(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.3) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "/home/dantle/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from diffusers import DDPMScheduler\n",
    "import joblib\n",
    "import scipy.sparse as sp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from dataclasses import dataclass\n",
    "import numpy as np\n",
    "import math, os, glob, torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy import sparse\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from diffusers import DDPMScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wandb Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdantle4564\u001b[0m (\u001b[33mdantle4564-uc-santa-barbara\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dantle/CacheBox/wandb/run-20251203_103236-a3ha2ftq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dantle4564-uc-santa-barbara/my-awesome-project/runs/a3ha2ftq' target=\"_blank\">curious-yogurt-35</a></strong> to <a href='https://wandb.ai/dantle4564-uc-santa-barbara/my-awesome-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dantle4564-uc-santa-barbara/my-awesome-project' target=\"_blank\">https://wandb.ai/dantle4564-uc-santa-barbara/my-awesome-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dantle4564-uc-santa-barbara/my-awesome-project/runs/a3ha2ftq' target=\"_blank\">https://wandb.ai/dantle4564-uc-santa-barbara/my-awesome-project/runs/a3ha2ftq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▆▅█▇▇██</td></tr><tr><td>loss</td><td>█▆▂▂▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>0.94238</td></tr><tr><td>loss</td><td>0.12036</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">curious-yogurt-35</strong> at: <a href='https://wandb.ai/dantle4564-uc-santa-barbara/my-awesome-project/runs/a3ha2ftq' target=\"_blank\">https://wandb.ai/dantle4564-uc-santa-barbara/my-awesome-project/runs/a3ha2ftq</a><br> View project at: <a href='https://wandb.ai/dantle4564-uc-santa-barbara/my-awesome-project' target=\"_blank\">https://wandb.ai/dantle4564-uc-santa-barbara/my-awesome-project</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251203_103236-a3ha2ftq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start a new wandb run to track this script.\n",
    "run = wandb.init(\n",
    "    # Set the wandb entity where your project will be logged (generally your team name).\n",
    "    entity=\"dantle4564-uc-santa-barbara\",\n",
    "    # Set the wandb project where this run will be logged.\n",
    "    project=\"my-awesome-project\",\n",
    "    # Track hyperparameters and run metadata.\n",
    "    config={\n",
    "        \"learning_rate\": 0.02,\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"CIFAR-100\",\n",
    "        \"epochs\": 10,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Simulate training.\n",
    "epochs = 10\n",
    "offset = random.random() / 5\n",
    "for epoch in range(2, epochs):\n",
    "    acc = 1 - 2**-epoch - random.random() / epoch - offset\n",
    "    loss = 2**-epoch + random.random() / epoch + offset\n",
    "\n",
    "    # Log metrics to wandb.\n",
    "    run.log({\"acc\": acc, \"loss\": loss})\n",
    "\n",
    "# Finish the run and upload any remaining data.\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOUBLE CHECK IN CASE HEATMAPS WERE NOT ADDED FOR SOME REASON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['401.bzip2-7B', '410.bwaves-1963B', '401.bzip2-226B', '429.mcf-217B', '435.gromacs-134B', '435.gromacs-226B', '429.mcf-51B', '429.mcf-192B', '410.bwaves-945B', '433.milc-337B', '410.bwaves-2097B', '435.gromacs-111B', '434.zeusmp-10B', '416.gamess-875B', '433.milc-274B', '429.mcf-184B', '401.bzip2-38B', '429.mcf-22B', '433.milc-127B']\n",
      "['401.bzip2-7B', '410.bwaves-1963B', '401.bzip2-226B', '410.bwaves-945B', '410.bwaves-2097B', '416.gamess-875B', '401.bzip2-277B', '401.bzip2-38B']\n",
      "FULL\n",
      "401.bzip2-7B 2055 .DS_Store\n",
      "410.bwaves-1963B 10075 410.bwaves-1963B.champsimtrace.xz.txt_12225_A.npz\n",
      "401.bzip2-226B 7978 401.bzip2-226B.champsimtrace.xz.txt_7977_A.npz\n",
      "429.mcf-217B 9852 429.mcf-217B.champsimtrace.xz.txt_9851_A.npz\n",
      "435.gromacs-134B 7004 435.gromacs-134B.champsimtrace.xz.txt_7003_A.npz\n",
      "435.gromacs-226B 7565 435.gromacs-226B.champsimtrace.xz.txt_7564_A.npz\n",
      "429.mcf-51B 7453 429.mcf-51B.champsimtrace.xz.txt_7452_A.npz\n",
      "429.mcf-192B 5811 429.mcf-192B.champsimtrace.xz.txt_5810_A.npz\n",
      "410.bwaves-945B 5408 410.bwaves-945B.champsimtrace.xz.txt_5407_A.npz\n",
      "433.milc-337B 3535 433.milc-337B.champsimtrace.xz.txt_3534_A.npz\n",
      "410.bwaves-2097B 5969 410.bwaves-2097B.champsimtrace.xz.txt_12012_A.npz\n",
      "435.gromacs-111B 7496 435.gromacs-111B.champsimtrace.xz.txt_7495_A.npz\n",
      "434.zeusmp-10B 5880 434.zeusmp-10B.champsimtrace.xz.txt_5879_A.npz\n",
      "416.gamess-875B 9377 416.gamess-875B.champsimtrace.xz.txt_9376_A.npz\n",
      "433.milc-274B 4106 433.milc-274B.champsimtrace.xz.txt_4105_A.npz\n",
      "429.mcf-184B 6827 429.mcf-184B.champsimtrace.xz.txt_6826_A.npz\n",
      "401.bzip2-38B 5805 401.bzip2-38B.champsimtrace.xz.txt_6224_A.npz\n",
      "429.mcf-22B 9845 .DS_Store\n",
      "433.milc-127B 6429 433.milc-127B.champsimtrace.xz.txt_6428_A.npz\n",
      "MISS\n",
      "401.bzip2-7B 1302 401.bzip2-7B.champsimtrace.xz.txt_1300_B.npz\n",
      "410.bwaves-1963B 1403 410.bwaves-1963B.champsimtrace.xz.txt_11262_B.npz\n",
      "401.bzip2-226B 7978 401.bzip2-226B.champsimtrace.xz.txt_7977_B.npz\n",
      "410.bwaves-945B 5408 410.bwaves-945B.champsimtrace.xz.txt_5407_B.npz\n",
      "410.bwaves-2097B 10069 410.bwaves-2097B.champsimtrace.xz.txt_12012_B.npz\n",
      "416.gamess-875B 9377 416.gamess-875B.champsimtrace.xz.txt_9376_B.npz\n",
      "401.bzip2-277B 6607 401.bzip2-277B.champsimtrace.xz.txt_6606_B.npz\n",
      "401.bzip2-38B 8541 401.bzip2-38B.champsimtrace.xz.txt_8540_B.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from natsort import natsorted\n",
    "\n",
    "root = Path(\"FULL_DATASET\")\n",
    "train_full_benchmarks = os.listdir(str(root / \"TRAIN\" / \"FULL\"))\n",
    "train_miss_benchmarks = os.listdir(str(root / \"TRAIN\" / \"MISS\"))\n",
    "print(train_full_benchmarks)\n",
    "print(train_miss_benchmarks)\n",
    "\n",
    "print(\"FULL\")\n",
    "for folder in train_full_benchmarks:\n",
    "    items = natsorted(os.listdir(str(root / \"TRAIN\" / \"FULL\" / folder)))\n",
    "    print(folder, len(items), items[-1])\n",
    "\n",
    "print(\"MISS\")\n",
    "for folder in train_miss_benchmarks:\n",
    "    items = natsorted(os.listdir(str(root / \"TRAIN\" / \"MISS\" / folder)))\n",
    "    print(folder, len(items), items[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "gqWKjsCOZKlF"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    image_size = 512 # the generated image resolution\n",
    "    train_batch_size = 1\n",
    "    eval_batch_size = 1  # how many images to sample during evaluation\n",
    "    num_epochs = 1\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    save_image_epochs = 10\n",
    "    save_model_epochs = 30\n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"diffusionTest\"  # the model name locally and on the HF Hub\n",
    "\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qjnYHCZ1jWhQ"
   },
   "outputs": [],
   "source": [
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.image_size,  # the target image resolution\n",
    "    in_channels=3,  # the number of input channels, 3 for RGB images\n",
    "    out_channels=3,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/dantle/CacheBox/wandb/run-20251203_103241-4m4m6yfc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dantle4564-uc-santa-barbara/CacheBoxDModel/runs/4m4m6yfc' target=\"_blank\">glamorous-disco-86</a></strong> to <a href='https://wandb.ai/dantle4564-uc-santa-barbara/CacheBoxDModel' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dantle4564-uc-santa-barbara/CacheBoxDModel' target=\"_blank\">https://wandb.ai/dantle4564-uc-santa-barbara/CacheBoxDModel</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dantle4564-uc-santa-barbara/CacheBoxDModel/runs/4m4m6yfc' target=\"_blank\">https://wandb.ai/dantle4564-uc-santa-barbara/CacheBoxDModel/runs/4m4m6yfc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"CacheBoxDModel\", entity=\"dantle4564-uc-santa-barbara\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_square(x1d):\n",
    "    L = x1d.shape[0]\n",
    "    s = int(math.ceil(math.sqrt(L)))\n",
    "    out = np.zeros(s*s, dtype=x1d.dtype)\n",
    "    out[:L] = x1d\n",
    "    return out.reshape(s, s)\n",
    "\n",
    "class HeatmapSmallDataset(Dataset):\n",
    "    def __init__(self, root, image_size=128):\n",
    "        self.root = Path(root)\n",
    "        self.image_size = int(image_size)\n",
    "        # only load 20 benchmarks\n",
    "        train_full_benchmarks = os.listdir(self.root / \"TRAIN\" / \"FULL\")[:21]\n",
    "        train_miss_benchmarks = os.listdir(self.root / \"TRAIN\" / \"MISS\")[:21]\n",
    "        full_files, miss_files = [],[]\n",
    "        for bench in train_full_benchmarks:\n",
    "            full_files += sorted(glob.glob(str(self.root / \"TRAIN\" / \"FULL\" / bench / \"*_A.npz\")))\n",
    "        for bench in train_miss_benchmarks:\n",
    "            miss_files += sorted(glob.glob(str(self.root / \"TRAIN\" / \"MISS\" / bench / \"*_B.npz\")))\n",
    "        # full_files = [p for p in full_files if p.endswith(\"_A.npz\")]\n",
    "        # miss_files = [p for p in miss_files if p.endswith(\"_B.npz\")]\n",
    "        self.files = full_files + miss_files\n",
    "        cleaned = []\n",
    "        # remove any 0 value .npz files\n",
    "        for f in self.files:\n",
    "            try:\n",
    "                # miss_sparse_mat = (sp.load_npz(path))\n",
    "                # miss_numpy_array = np.array(miss_sparse_mat.toarray(), dtype = np.uint8)\n",
    "                # return miss_numpy_array\n",
    "                with np.load(f, allow_pickle=False) as npz:\n",
    "                    k = \"arr_0\" if \"arr_0\" in npz.files else next(kk for kk in npz.files if isinstance(npz[kk], np.ndarray))\n",
    "                    arr = np.array(npz[k])\n",
    "                if arr.size == 0 or not np.isfinite(arr).any(): continue\n",
    "                cleaned.append(f)\n",
    "            except Exception:\n",
    "                pass\n",
    "        self.files = cleaned\n",
    "        if not self.files:\n",
    "            raise FileNotFoundError(\"No valid npz files found\")\n",
    "    def __len__(self): return len(self.files)\n",
    "    def __getitem__(self, idx):\n",
    "        # load files into npz\n",
    "        with np.load(self.files[idx], allow_pickle=False) as npz:\n",
    "            k = \"arr_0\" if \"arr_0\" in npz.files else next(kk for kk in npz.files if isinstance(npz[kk], np.ndarray))\n",
    "            x = np.array(npz[k], dtype=np.float32)\n",
    "        if x.ndim == 1: x = vector_to_square(x)\n",
    "        elif x.ndim > 2: x = x[0]\n",
    "        xmin, xmax = np.min(x), np.max(x)\n",
    "        x = (x - xmin) / (xmax - xmin) if xmax > xmin else np.zeros_like(x, dtype=np.float32)\n",
    "        x = torch.from_numpy(x)\n",
    "        if x.ndim == 2: x = x.unsqueeze(0)\n",
    "        elif x.ndim == 3 and x.shape[0] not in (1,3): x = x.permute(2,0,1)\n",
    "        if x.shape[0] == 1: x = x.repeat(3,1,1)\n",
    "        elif x.shape[0] > 3: x = x[:3]\n",
    "        x = F.interpolate(x.unsqueeze(0), size=(self.image_size, self.image_size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        x = x * 2 - 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAKE SURE YOU ARE RUNNING ON GPU NOT CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Dec  3 10:32:43 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.261.03             Driver Version: 535.261.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:B3:00.0 Off |                  N/A |\n",
      "| 44%   50C    P8              32W / 350W |     26MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1060      G   /usr/lib/xorg/Xorg                            9MiB |\n",
      "|    0   N/A  N/A      1135      G   /usr/bin/gnome-shell                          6MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device: NVIDIA GeForce RTX 3090\n",
      "tensor([[0.7799, 0.3640, 0.3493],\n",
      "        [0.7623, 0.3210, 0.5388],\n",
      "        [0.4987, 0.9869, 0.2862]], device='cuda:0')\n",
      "x.device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Device:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "x = torch.rand(3, 3, device=\"cuda\")\n",
    "print(x)\n",
    "print(\"x.device:\", x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = HeatmapSmallDataset(\"/home/pranjali_jain/NCS/sparse-matrices/SPEC/SPEC189_2config/1-64-12\", image_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset & Configure Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure dataloader sec/batch: 0.0064629590511322025\n",
      "314017 torch.Size([1, 3, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "root = \"/home/pranjali_jain/NCS/sparse-matrices/SPEC/SPEC189_2config/1-64-12/\"\n",
    "image_size = int(config.image_size) # 512x512\n",
    "ds = HeatmapSmallDataset(root, image_size=image_size)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "loader = DataLoader(ds, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "\n",
    "import time\n",
    "it = iter(loader)\n",
    "start = time.time()\n",
    "for _ in range(200):\n",
    "    batch = next(it)\n",
    "end = time.time()\n",
    "print(\"Pure dataloader sec/batch:\", (end - start)/200)\n",
    "\n",
    "batch = next(iter(loader))\n",
    "print(len(ds), batch.shape)\n",
    "\n",
    "model = model.to(device)\n",
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 577
    },
    "id": "PC3IlD7zY0so",
    "outputId": "7ec910ae-1eac-4661-dd65-e2d210b9ddee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-abc2e3738753>:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-abc2e3738753>:15: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    }
   ],
   "source": [
    "# run = wandb.init(project=\"CacheBoxDModel\", entity=\"dantle4564-uc-santa-barbara\", name=\"CacheBoxTestRun\")\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "\n",
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for step, batch in enumerate(loader, 1):\n",
    "        batch = batch.to(device)\n",
    "        t = torch.randint(0, noise_scheduler.config.num_train_timesteps, (batch.size(0),), device=device)\n",
    "        noise = torch.randn_like(batch)\n",
    "        noisy = noise_scheduler.add_noise(batch, noise, t)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast():\n",
    "            pred = model(noisy, t, return_dict=False)[0]\n",
    "            loss = torch.nn.functional.l1_loss(pred, noise)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    # print(f\"epoch {epoch+1}/{num_epochs} | loss {loss.item():.4f}\")\n",
    "    # wandb.log({\"loss\": loss.item()})\n",
    "# run.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE & LOAD MODEL AFTER TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filename = 'cache_heatmap_diffusion_model_.sav' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, open(filename, 'wb')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "wandb.init(project=\"CacheBoxDModel\", entity=\"dantle4564-uc-santa-barbara\", name=\"diffusion images\")\n",
    "\n",
    "scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "# generate only one image\n",
    "num = 1\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "image_size = 512\n",
    "\n",
    "with torch.no_grad():\n",
    "    x = torch.randn(num, 3, image_size, image_size, device=device)\n",
    "    scheduler.set_timesteps(scheduler.config.num_train_timesteps)\n",
    "    for i,t in enumerate(scheduler.timesteps):\n",
    "        with torch.cuda.amp.autocast(enabled=(device.type == \"cuda\")):\n",
    "            model_input = scheduler.scale_model_input(x, t)\n",
    "            noise_pred = model(model_input, t).sample\n",
    "            x = scheduler.step(noise_pred, t, x).prev_sample\n",
    "            if i % 10 == 0: \n",
    "                img = (x.clamp(-1, 1) + 1) / 2  # scale to [0,1]\n",
    "                img_np = T.ToPILImage()(img[0].cpu())\n",
    "                wandb.log({f\"Time step {i}\" : wandb.Image(img_np)})\n",
    "        \n",
    "    # save the single image\n",
    "    img = (x.clamp(-1, 1) + 1) / 2\n",
    "    print(img.type)\n",
    "    print(\"Image shape:\" , img.shape)\n",
    "    arr0 = arr[0]                          # (3, H, W)\n",
    "\n",
    "    # Option A: pixels as rows, channels as cols -> (H*W, 3)\n",
    "    H, W = arr0.shape[1], arr0.shape[2]\n",
    "    mat2d = arr0.reshape(3, H * W).T       # (H*W, 3)\n",
    "    sparse_mat = sparse.csr_matrix(mat2d)\n",
    "    sparse.save_npz(\"synthetic_heatmap.npz\", sparse_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths\n",
    "# python3 configwise_hitrate.py\n",
    "# <real full heat map dir> = small_dataset/TEST/FULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0CbMn7oia7s"
   },
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "data1 = sp.load_npz(\"/home/dantle/CacheBox/small_dataset/TEST/MISS/400.perlbench-41B/400.perlbench-50B.champsimtrace.xz.txt_0_B.npz\")\n",
    "data2 = sp.load_npz(\"/home/dantle/CacheBox/synthetic_heatmap.npz\")\n",
    "\n",
    "# print(data1.files)\n",
    "# print(data2.files)\n",
    "print(type(data1))\n",
    "print(data1.shape)\n",
    "print(data1.nnz)\n",
    "img1 =  np.array(data1.toarray(), dtype = np.uint8)\n",
    "# img2 = data2['arr_0']\n",
    "# print(\"Shape 1:\", img1.shape)\n",
    "# print(\"Shape 2:\", img2.shape)\n",
    "\n",
    "\n",
    "#score, diff = ssim(img1, img2, full=True)\n",
    "\n",
    "#print(\"SSIM:\", score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBZNXTdtjGdW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import load_npz\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.transform import resize\n",
    "\n",
    "# ---- 1. Load sparse test heatmap and make it dense ----\n",
    "test_sp = load_npz(\"/home/dantle/CacheBox/small_dataset/TEST/MISS/400.perlbench-41B/400.perlbench-50B.champsimtrace.xz.txt_1_B.npz\")    # your existing .npz\n",
    "test_img = test_sp.toarray().astype(np.float32)  # shape: (512, 512)\n",
    "\n",
    "# ---- 2. Load your synthetic dense heatmap ----\n",
    "data = np.load(\"/home/dantle/CacheBox/synthetic_heatmap.npz\")\n",
    "# adjust key as needed:\n",
    "synthetic = list(data.values())[0]               # or data[\"heatmap\"]\n",
    "\n",
    "# If synthetic came from (1, 3, 128, 128) torch tensor:\n",
    "if synthetic.ndim == 4:\n",
    "    # (1, 3, 128, 128) -> (3, 128, 128)\n",
    "    synthetic = synthetic.squeeze(0)\n",
    "\n",
    "if synthetic.ndim == 3:\n",
    "    # collapse channels to grayscale (3, H, W) -> (H, W)\n",
    "    synthetic = synthetic.mean(axis=0)\n",
    "\n",
    "# Now synthetic is (H, W), probably (128, 128)\n",
    "\n",
    "# ---- 3. Resize synthetic to match (512, 512) ----\n",
    "synthetic_resized = resize(\n",
    "    synthetic, \n",
    "    test_img.shape,       # (512, 512)\n",
    "    anti_aliasing=True\n",
    ").astype(np.float32)\n",
    "\n",
    "print(test_img.shape)\n",
    "# print(test_img)\n",
    "print(synthetic_resized.shape)\n",
    "# ---- 4. Compute SSIM ----\n",
    "score, diff = ssim(test_img, synthetic_resized, full=True, data_range=1.0)\n",
    "print(\"SSIM:\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = 'magma_r' #'PuOr'#\n",
    "plt.style.use('seaborn-v0_8-deep')\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.serif'] = ['Helvetica']\n",
    "Fontsize = 20\n",
    "plt.rcParams['font.size'] = Fontsize\n",
    "\n",
    "plt.rcParams['axes.facecolor'] = 'white'  \n",
    "plt.rcParams['text.color'] = 'black'  \n",
    "plt.rcParams['axes.labelcolor'] = 'black'  \n",
    "plt.rcParams['xtick.color'] = 'black' \n",
    "plt.rcParams['ytick.color'] = 'black'  \n",
    "plt.rcParams['axes.edgecolor'] = 'black'  \n",
    "plt.rcParams['axes.linewidth'] = 1.0\n",
    "plt.rcParams['legend.handlelength'] = 0.7\n",
    "plt.rcParams['legend.handleheight'] = 0.7\n",
    "plt.rcParams['ytick.major.size'] = 4\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "\n",
    "stepval = 256\n",
    "\n",
    "figure, (ax1) = plt.subplots(1,1, figsize=(5, 5))\n",
    "figure.patch.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "ax1.imshow(test_img, cmap=colormap)\n",
    "# ax1.axis('off')\n",
    "# ax1.set_title('Real full map')\n",
    "ax1.set_xticks(ticks = np.arange(0, 513, step=stepval))\n",
    "ax1.set_yticks(ticks = np.arange(0, 513, step=stepval))\n",
    "plt.xticks(fontsize=Fontsize-2)\n",
    "plt.yticks(fontsize=Fontsize-2)\n",
    "plt.ylabel('cacheline address\\nmodulo 512',labelpad=8)\n",
    "plt.xlabel('Instructions',labelpad=8)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"Graphs/heatmap_1x1_realfull\", dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = 'magma_r' #'PuOr'#\n",
    "plt.style.use('seaborn-v0_8-deep')\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.serif'] = ['Helvetica']\n",
    "Fontsize = 20\n",
    "plt.rcParams['font.size'] = Fontsize\n",
    "\n",
    "plt.rcParams['axes.facecolor'] = 'white'  \n",
    "plt.rcParams['text.color'] = 'black'  \n",
    "plt.rcParams['axes.labelcolor'] = 'black'  \n",
    "plt.rcParams['xtick.color'] = 'black' \n",
    "plt.rcParams['ytick.color'] = 'black'  \n",
    "plt.rcParams['axes.edgecolor'] = 'black'  \n",
    "plt.rcParams['axes.linewidth'] = 1.0\n",
    "plt.rcParams['legend.handlelength'] = 0.7\n",
    "plt.rcParams['legend.handleheight'] = 0.7\n",
    "plt.rcParams['ytick.major.size'] = 4\n",
    "plt.rcParams['ytick.major.width'] = 1\n",
    "\n",
    "stepval = 256\n",
    "\n",
    "figure, (ax1) = plt.subplots(1,1, figsize=(5, 5))\n",
    "figure.patch.set_facecolor(\"white\")\n",
    "\n",
    "\n",
    "ax1.imshow(synthetic_resized, cmap=colormap)\n",
    "# ax1.axis('off')\n",
    "# ax1.set_title('Real full map')\n",
    "ax1.set_xticks(ticks = np.arange(0, 513, step=stepval))\n",
    "ax1.set_yticks(ticks = np.arange(0, 513, step=stepval))\n",
    "plt.xticks(fontsize=Fontsize-2)\n",
    "plt.yticks(fontsize=Fontsize-2)\n",
    "plt.ylabel('cacheline address\\nmodulo 512',labelpad=8)\n",
    "plt.xlabel('Instructions',labelpad=8)\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"Graphs/heatmap_1x1_realfull\", dpi=300, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
